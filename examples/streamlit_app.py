"""
Streamlit Webç•Œé¢
ä¸ºDeep Search Agentæä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import warnings
import json
import hashlib
from pathlib import Path

# å¿½ç•¥ Streamlit åª’ä½“æ–‡ä»¶å­˜å‚¨é”™è¯¯ï¼ˆè¿™æ˜¯ Streamlit çš„å†…éƒ¨é—®é¢˜ï¼Œä¸å½±å“åŠŸèƒ½ï¼‰
warnings.filterwarnings('ignore', category=UserWarning, module='streamlit')

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from deep_research import DeepSearchAgent, Config


def get_historical_reports(output_dir="streamlit_reports"):
    """è·å–å†å²æŠ¥å‘Šåˆ—è¡¨"""
    reports = []
    if not os.path.exists(output_dir):
        return reports
    
    for file in Path(output_dir).glob("deep_search_report_*.md"):
        # è·å–æ–‡ä»¶ä¿¡æ¯
        stat = file.stat()
        file_info = {
            'filename': file.name,
            'filepath': str(file),
            'modified_time': datetime.fromtimestamp(stat.st_mtime),
            'size': stat.st_size
        }
        
        # å°è¯•æ‰¾åˆ°å¯¹åº”çš„çŠ¶æ€æ–‡ä»¶
        state_file = file.with_name(file.name.replace('deep_search_report_', 'state_').replace('.md', '.json'))
        if state_file.exists():
            file_info['state_file'] = str(state_file)
        
        reports.append(file_info)
    
    # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
    reports.sort(key=lambda x: x['modified_time'], reverse=True)
    return reports


def update_status_info(container):
    """æ›´æ–°çŠ¶æ€ä¿¡æ¯æ˜¾ç¤º"""
    if 'agent' in st.session_state and hasattr(st.session_state.agent, 'state'):
        progress = st.session_state.agent.get_progress_summary()
        with container.container():
            st.metric("æ€»æ®µè½æ•°", progress['total_paragraphs'])
            st.metric("å·²å®Œæˆ", progress['completed_paragraphs'])
            st.progress(progress['progress_percentage'] / 100)
    else:
        container.info("å°šæœªå¼€å§‹ç ”ç©¶")


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="Deep Search Agent",
        page_icon="ğŸ”",
        layout="wide"
    )

    st.title("Deep Search Agent")
    st.markdown("åŸºäºDeepSeekçš„æ— æ¡†æ¶æ·±åº¦æœç´¢AIä»£ç†")
    
    # é¡¶éƒ¨å¯¼èˆªé€‰é¡¹å¡
    main_tab, history_tab = st.tabs(["ğŸ” æ–°å»ºç ”ç©¶", "ğŸ“š å†å²æŠ¥å‘Š"])

    # å†å²æŠ¥å‘Šæ ‡ç­¾é¡µ
    with history_tab:
        show_historical_reports()
    
    # æ–°å»ºç ”ç©¶æ ‡ç­¾é¡µ
    with main_tab:
        run_new_research()


def show_historical_reports():
    """æ˜¾ç¤ºå†å²æŠ¥å‘Š"""
    st.header("ğŸ“š å†å²æŠ¥å‘Š")
    
    # è·å–å†å²æŠ¥å‘Š
    reports = get_historical_reports()
    
    if not reports:
        st.info("æš‚æ— å†å²æŠ¥å‘Šã€‚å¼€å§‹ä¸€ä¸ªæ–°ç ”ç©¶æ¥ç”Ÿæˆä½ çš„ç¬¬ä¸€ä»½æŠ¥å‘Šï¼")
        return
    
    st.markdown(f"å…±æ‰¾åˆ° **{len(reports)}** ä»½å†å²æŠ¥å‘Š")
    
    # æ·»åŠ æœç´¢å’Œç­›é€‰åŠŸèƒ½
    col1, col2 = st.columns([3, 1])
    with col1:
        search_term = st.text_input("ğŸ” æœç´¢æŠ¥å‘Š", placeholder="è¾“å…¥å…³é”®è¯æœç´¢...")
    with col2:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["æœ€æ–°ä¼˜å…ˆ", "æœ€æ—§ä¼˜å…ˆ", "æ–‡ä»¶å"])
    
    # ç­›é€‰æŠ¥å‘Š
    filtered_reports = reports
    if search_term:
        filtered_reports = [r for r in reports if search_term.lower() in r['filename'].lower()]
    
    # æ’åº
    if sort_by == "æœ€æ—§ä¼˜å…ˆ":
        filtered_reports.sort(key=lambda x: x['modified_time'])
    elif sort_by == "æ–‡ä»¶å":
        filtered_reports.sort(key=lambda x: x['filename'])
    
    if not filtered_reports:
        st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æŠ¥å‘Š")
        return
    
    # æ˜¾ç¤ºæŠ¥å‘Šåˆ—è¡¨
    for i, report in enumerate(filtered_reports):
        with st.expander(
            f"ğŸ“„ {report['filename']} | {report['modified_time'].strftime('%Y-%m-%d %H:%M:%S')} | {report['size'] / 1024:.1f} KB",
            expanded=(i == 0)  # é»˜è®¤å±•å¼€ç¬¬ä¸€ä¸ª
        ):
            # è¯»å–æŠ¥å‘Šå†…å®¹
            try:
                with open(report['filepath'], 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åˆ›å»ºå­æ ‡ç­¾
                if 'state_file' in report:
                    report_tab, state_tab, download_tab = st.tabs(["æŠ¥å‘Šå†…å®¹", "çŠ¶æ€ä¿¡æ¯", "ä¸‹è½½"])
                else:
                    report_tab, download_tab = st.tabs(["æŠ¥å‘Šå†…å®¹", "ä¸‹è½½"])
                
                with report_tab:
                    st.markdown(content)
                
                # çŠ¶æ€ä¿¡æ¯æ ‡ç­¾
                if 'state_file' in report:
                    with state_tab:
                        try:
                            with open(report['state_file'], 'r', encoding='utf-8') as f:
                                state_data = json.load(f)
                            
                            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                            st.subheader("åŸºæœ¬ä¿¡æ¯")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("æŸ¥è¯¢", state_data.get('query', 'N/A'))
                            with col2:
                                st.metric("æ®µè½æ•°", len(state_data.get('paragraphs', [])))
                            with col3:
                                st.metric("çŠ¶æ€", state_data.get('status', 'N/A'))
                            
                            # æ˜¾ç¤ºæ®µè½è¯¦æƒ…
                            if 'paragraphs' in state_data:
                                st.subheader("æ®µè½è¯¦æƒ…")
                                for j, para in enumerate(state_data['paragraphs']):
                                    with st.expander(f"æ®µè½ {j+1}: {para.get('title', 'N/A')}"):
                                        st.write("**é¢„æœŸå†…å®¹:**", para.get('content', 'N/A'))
                                        if 'research' in para:
                                            research = para['research']
                                            st.write("**æœç´¢æ¬¡æ•°:**", len(research.get('search_history', [])))
                                            st.write("**åæ€æ¬¡æ•°:**", research.get('reflection_iteration', 0))
                                            latest_summary = research.get('latest_summary', '')
                                            if latest_summary:
                                                st.write("**æœ€ç»ˆæ€»ç»“:**", latest_summary[:300] + "..." if len(latest_summary) > 300 else latest_summary)
                        except Exception as e:
                            st.error(f"è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: {str(e)}")
                
                # ä¸‹è½½æ ‡ç­¾
                with download_tab:
                    col1, col2 = st.columns(2)
                    
                    # ä¸ºæ¯ä¸ªä¸‹è½½æŒ‰é’®ç”Ÿæˆå”¯ä¸€çš„ keyï¼Œä½¿ç”¨æ—¶é—´æˆ³å’Œç´¢å¼•é¿å…å†²çª
                    unique_id = f"{report['modified_time'].timestamp()}_{i}"
                    
                    with col1:
                        # æ¯æ¬¡éƒ½é‡æ–°ç¼–ç æ•°æ®ï¼Œé¿å…ç¼“å­˜é—®é¢˜
                        report_data = content.encode('utf-8')
                        st.download_button(
                            label="ğŸ“„ ä¸‹è½½MarkdownæŠ¥å‘Š",
                            data=report_data,
                            file_name=report['filename'],
                            mime="text/markdown",
                            key=f"dl_md_{unique_id}",
                            use_container_width=True
                        )
                    
                    with col2:
                        if 'state_file' in report:
                            try:
                                with open(report['state_file'], 'r', encoding='utf-8') as f:
                                    state_content = f.read()
                                state_data = state_content.encode('utf-8')
                                st.download_button(
                                    label="ğŸ“Š ä¸‹è½½çŠ¶æ€æ–‡ä»¶",
                                    data=state_data,
                                    file_name=os.path.basename(report['state_file']),
                                    mime="application/json",
                                    key=f"dl_json_{unique_id}",
                                    use_container_width=True
                                )
                            except Exception as e:
                                st.warning(f"çŠ¶æ€æ–‡ä»¶ä¸‹è½½æš‚æ—¶ä¸å¯ç”¨")
                        else:
                            st.info("æ— çŠ¶æ€æ–‡ä»¶")
                    
                    # åˆ é™¤æŒ‰é’®
                    st.divider()
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤æ­¤æŠ¥å‘Š", key=f"del_{unique_id}", type="secondary", use_container_width=True):
                        try:
                            os.remove(report['filepath'])
                            if 'state_file' in report and os.path.exists(report['state_file']):
                                os.remove(report['state_file'])
                            st.success("æŠ¥å‘Šå·²åˆ é™¤ï¼")
                            st.rerun()
                        except Exception as e:
                            st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")
                            
            except Exception as e:
                st.error(f"è¯»å–æŠ¥å‘Šå¤±è´¥: {str(e)}")


def run_new_research():
    """è¿è¡Œæ–°ç ”ç©¶çš„ç•Œé¢"""
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("é…ç½®")

        # APIå¯†é’¥é…ç½®
        st.subheader("APIå¯†é’¥")
        deepseek_key = st.text_input("DeepSeek API Key", type="password",
                                   value="")

        tavily_key = st.text_input("Tavily API Key", type="password",
                                 value="")

        # é«˜çº§é…ç½®
        st.subheader("é«˜çº§é…ç½®")
        max_reflections = st.slider("åæ€æ¬¡æ•°", 1, 5, 2)
        max_search_results = st.slider("æœç´¢ç»“æœæ•°", 1, 10, 3)
        max_content_length = st.number_input("æœ€å¤§å†…å®¹é•¿åº¦", 1000, 50000, 20000)

        # æ¨¡å‹é€‰æ‹©
        llm_provider = st.selectbox("LLMæä¾›å•†", ["deepseek", "openai"])

        if llm_provider == "deepseek":
            model_name = st.selectbox("DeepSeekæ¨¡å‹", ["deepseek-chat"])
        else:
            model_name = st.selectbox("OpenAIæ¨¡å‹", ["gpt-4o-mini", "gpt-4o"])
            openai_key = st.text_input("OpenAI API Key", type="password",
                                     value="")

    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("ç ”ç©¶æŸ¥è¯¢")
        query = st.text_area(
            "è¯·è¾“å…¥æ‚¨è¦ç ”ç©¶çš„é—®é¢˜",
            placeholder="ä¾‹å¦‚ï¼š2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
            height=100
        )

        # é¢„è®¾æŸ¥è¯¢ç¤ºä¾‹
        st.subheader("ç¤ºä¾‹æŸ¥è¯¢")
        example_queries = [
            "2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
            "æ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
            "åŒºå—é“¾æŠ€æœ¯çš„æœ€æ–°å‘å±•",
            "å¯æŒç»­èƒ½æºæŠ€æœ¯è¶‹åŠ¿",
            "é‡å­è®¡ç®—çš„å‘å±•ç°çŠ¶"
        ]

        selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹æŸ¥è¯¢", ["è‡ªå®šä¹‰"] + example_queries)
        if selected_example != "è‡ªå®šä¹‰":
            query = selected_example

    with col2:
        st.header("çŠ¶æ€ä¿¡æ¯")
        # ä½¿ç”¨ empty å®¹å™¨ä»¥ä¾¿åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æ›´æ–°çŠ¶æ€ä¿¡æ¯
        status_container = st.empty()
        # åˆå§‹åŒ–æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        update_status_info(status_container)

    # æ‰§è¡ŒæŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        start_research = st.button("å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True)

    # å¦‚æœç ”ç©¶å·²å®Œæˆï¼Œæ˜¾ç¤ºç»“æœï¼ˆé¡µé¢é‡æ–°åŠ è½½åä¹Ÿèƒ½æ˜¾ç¤ºï¼‰
    if st.session_state.get('research_completed', False) and 'agent' in st.session_state:
        agent = st.session_state.agent
        final_report = st.session_state.get('final_report', '')
        if final_report:
            display_results(agent, final_report)

    # éªŒè¯é…ç½®
    if start_research:
        # æ¸…é™¤ä¹‹å‰çš„ç ”ç©¶ç»“æœçŠ¶æ€ï¼Œé¿å…æ˜¾ç¤ºæ—§ç»“æœ
        if 'research_completed' in st.session_state:
            st.session_state.research_completed = False
        if 'download_timestamp' in st.session_state:
            del st.session_state.download_timestamp
        if 'download_key_base' in st.session_state:
            del st.session_state.download_key_base

        if not query.strip():
            st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            return

        if not deepseek_key and llm_provider == "deepseek":
            st.error("è¯·æä¾›DeepSeek API Key")
            return

        if not tavily_key:
            st.error("è¯·æä¾›Tavily API Key")
            return

        if llm_provider == "openai" and not openai_key:
            st.error("è¯·æä¾›OpenAI API Key")
            return

        # åˆ›å»ºé…ç½®
        config = Config(
            deepseek_api_key=deepseek_key if llm_provider == "deepseek" else None,
            openai_api_key=openai_key if llm_provider == "openai" else None,
            tavily_api_key=tavily_key,
            default_llm_provider=llm_provider,
            deepseek_model=model_name if llm_provider == "deepseek" else "deepseek-chat",
            openai_model=model_name if llm_provider == "openai" else "gpt-4o-mini",
            max_reflections=max_reflections,
            max_search_results=max_search_results,
            max_content_length=max_content_length,
            output_dir="streamlit_reports"
        )

        # æ‰§è¡Œç ”ç©¶ï¼ˆä¼ å…¥çŠ¶æ€å®¹å™¨ç”¨äºå®æ—¶æ›´æ–°ï¼‰
        execute_research(query, config, status_container)


def execute_research(query: str, config: Config, status_container=None):
    """æ‰§è¡Œç ”ç©¶"""
    try:
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–Agent
        status_text.text("æ­£åœ¨åˆå§‹åŒ–Agent...")
        agent = DeepSearchAgent(config)
        st.session_state.agent = agent

        # ç«‹å³æ›´æ–°çŠ¶æ€ä¿¡æ¯é¢æ¿
        if status_container:
            update_status_info(status_container)

        progress_bar.progress(10)

        # ç”ŸæˆæŠ¥å‘Šç»“æ„
        status_text.text("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æ„...")
        agent._generate_report_structure(query)

        # æ›´æ–°çŠ¶æ€ä¿¡æ¯ï¼ˆæŠ¥å‘Šç»“æ„å·²ç”Ÿæˆï¼Œæ®µè½æ•°å·²ç¡®å®šï¼‰
        if status_container:
            update_status_info(status_container)

        progress_bar.progress(20)

        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.text(f"æ­£åœ¨å¤„ç†æ®µè½ {i+1}/{total_paragraphs}: {agent.state.paragraphs[i].title}")

            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            if status_container:
                update_status_info(status_container)

            # åæ€å¾ªç¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()

            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

            # æ›´æ–°çŠ¶æ€ä¿¡æ¯ï¼ˆæ®µè½å¤„ç†å®Œæˆï¼‰
            if status_container:
                update_status_info(status_container)

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.text("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)

        # ä¿å­˜æŠ¥å‘Š
        status_text.text("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        agent._save_report(final_report)
        progress_bar.progress(100)

        status_text.text("ç ”ç©¶å®Œæˆï¼")

        # å°†ç»“æœä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ï¼Œé¿å…é‡å¤ç”Ÿæˆä¸‹è½½æŒ‰é’®
        st.session_state.final_report = final_report
        st.session_state.research_completed = True
        # è®¾ç½®ä¸‹è½½æ—¶é—´æˆ³ï¼Œç¡®ä¿ä¸‹è½½æŒ‰é’®ä½¿ç”¨ç¨³å®šçš„key
        st.session_state.download_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # æ˜¾ç¤ºç»“æœ
        display_results(agent, final_report)

    except Exception as e:
        st.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.session_state.research_completed = False


def display_results(agent: DeepSearchAgent, final_report: str):
    """æ˜¾ç¤ºç ”ç©¶ç»“æœ"""
    # åªåœ¨ç ”ç©¶å®Œæˆæ—¶æ˜¾ç¤ºç»“æœ
    if not st.session_state.get('research_completed', False):
        return

    # ä»ä¼šè¯çŠ¶æ€è·å–æŠ¥å‘Šï¼Œé¿å…é‡å¤åˆ›å»ºä¸‹è½½æŒ‰é’®
    final_report = st.session_state.get('final_report', final_report)

    st.header("ç ”ç©¶ç»“æœ")

    # ç»“æœæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["æœ€ç»ˆæŠ¥å‘Š", "è¯¦ç»†ä¿¡æ¯", "ä¸‹è½½"])

    with tab1:
        st.markdown(final_report)

    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i+1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..."
                        if len(paragraph.research.latest_summary) > 300
                        else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)

        # æœç´¢å†å²
        st.subheader("æœç´¢å†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)

        if all_searches:
            for i, search in enumerate(all_searches):
                with st.expander(f"æœç´¢ {i+1}: {search.query}"):
                    st.write("**URL:**", search.url)
                    st.write("**æ ‡é¢˜:**", search.title)
                    st.write("**å†…å®¹é¢„è§ˆ:**", search.content[:200] + "..." if len(search.content) > 200 else search.content)
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)

    with tab3:
        # ä¸‹è½½é€‰é¡¹
        st.subheader("ä¸‹è½½æŠ¥å‘Š")

        # è·å–æ—¶é—´æˆ³ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆæ–°çš„
        timestamp = st.session_state.get('download_timestamp', datetime.now().strftime('%Y%m%d_%H%M%S'))
        
        if final_report:
            # æ¯æ¬¡éƒ½é‡æ–°ç”Ÿæˆä¸‹è½½æ•°æ®ï¼Œé¿å…ç¼“å­˜é—®é¢˜
            col1, col2 = st.columns(2)
            
            # ç”Ÿæˆå”¯ä¸€IDç”¨äºæŒ‰é’®keyï¼Œç¡®ä¿å”¯ä¸€æ€§
            unique_key = hashlib.md5(f"{timestamp}_{id(final_report)}".encode()).hexdigest()[:8]
            
            with col1:
                # MarkdownæŠ¥å‘Šä¸‹è½½
                try:
                    report_bytes = final_report.encode('utf-8')
                    st.download_button(
                        label="ğŸ“„ ä¸‹è½½MarkdownæŠ¥å‘Š",
                        data=report_bytes,
                        file_name=f"deep_search_report_{timestamp}.md",
                        mime="text/markdown",
                        key=f"new_dl_md_{unique_key}",
                        use_container_width=True
                    )
                except Exception as e:
                    st.warning("ä¸‹è½½æŒ‰é’®æš‚æ—¶ä¸å¯ç”¨")
                    if hasattr(agent, 'config'):
                        output_dir = getattr(agent.config, 'output_dir', 'streamlit_reports')
                        st.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir}/deep_search_report_*.md")
            
            with col2:
                # JSONçŠ¶æ€ä¸‹è½½
                try:
                    if 'agent' in st.session_state and hasattr(st.session_state.agent, 'state'):
                        state_json = agent.state.to_json()
                        if state_json:
                            state_bytes = state_json.encode('utf-8')
                            st.download_button(
                                label="ğŸ“Š ä¸‹è½½çŠ¶æ€æ–‡ä»¶",
                                data=state_bytes,
                                file_name=f"deep_search_state_{timestamp}.json",
                                mime="application/json",
                                key=f"new_dl_json_{unique_key}",
                                use_container_width=True
                            )
                except Exception as e:
                    st.warning("çŠ¶æ€æ–‡ä»¶ä¸‹è½½æš‚æ—¶ä¸å¯ç”¨")
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿å­˜ä½ç½®
            st.divider()
            if hasattr(agent, 'config'):
                output_dir = getattr(agent.config, 'output_dir', 'streamlit_reports')
                st.success(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°æœ¬åœ°: `{output_dir}/`")
                st.info("ğŸ’¡ æç¤º: å¦‚æœä¸‹è½½æŒ‰é’®ä¸å¯ç”¨ï¼Œå¯ä»¥åœ¨ã€Œå†å²æŠ¥å‘Šã€æ ‡ç­¾é¡µä¸­æŸ¥çœ‹å’Œä¸‹è½½")


if __name__ == "__main__":
    # å½“ç›´æ¥ä½¿ç”¨ `python streamlit_app.py` è¿è¡Œæ—¶ï¼Œè‡ªåŠ¨ä»¥ `streamlit run` å¯åŠ¨ï¼Œé¿å…ç¼ºå¤± ScriptRunContext è­¦å‘Š
    try:
        import streamlit.web.cli as stcli
        sys.argv = ["streamlit", "run", os.path.abspath(__file__)]
        sys.exit(stcli.main())
    except Exception:
        # å›é€€åˆ°è£¸è¿è¡Œï¼ˆä¸ä¼šæ‰“å¼€æµè§ˆå™¨ï¼Œå¯èƒ½å‡ºç° ScriptRunContext æç¤ºï¼‰
        main()
